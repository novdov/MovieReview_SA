{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf & Multinomial NB using `soynlp` & `soyspacing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "from words_preprocessing import *\n",
    "from file_io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `soynlp`로 토크나이징한 데이터를 이용한 학습\n",
    "### 기존 모델(`twitter`, 교정X)의 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# [[16247   984   280   768   177]\n",
    "#  [ 1238  7903   553   230   171]\n",
    "#  [  579   966  3319   145    49]\n",
    "#  [ 1334   502   116  3178    91]\n",
    "#  [  474   425   100   138  1486]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.82      0.88      0.85     18456\n",
    "#            1       0.73      0.78      0.76     10095\n",
    "#            2       0.76      0.66      0.70      5058\n",
    "#            3       0.71      0.61      0.66      5221\n",
    "#            4       0.75      0.57      0.65      2623\n",
    "\n",
    "#  avg / total       0.77      0.78      0.77     41453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149230, 16580)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_pickle('../train_space_tokenized.pkl')\n",
    "test = load_pickle('../test_space_tokenized.pkl')\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111922, 37308, 111922, 37308)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = [row[1] for row in train]\n",
    "x0 = [' '.join(row[0]) for row in train]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, y0, \n",
    "                                                    random_state=1234)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.73827392  0.74272951  0.73825054  0.74236061  0.74583389]\n",
      "CPU times: user 45 s, sys: 1.87 s, total: 46.9 s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14885   862   186   441    74]\n",
      " [ 1583  6991   368   153    95]\n",
      " [  759  1107  2571   106    24]\n",
      " [ 1709   504   111  2301    51]\n",
      " [  699   519    93   113  1003]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.90      0.83     16448\n",
      "          1       0.70      0.76      0.73      9190\n",
      "          2       0.77      0.56      0.65      4567\n",
      "          3       0.74      0.49      0.59      4676\n",
      "          4       0.80      0.41      0.55      2427\n",
      "\n",
      "avg / total       0.75      0.74      0.73     37308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = [row[1] for row in test]\n",
    "test_data = [' '.join(row[0]) for row in test]\n",
    "\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6678  375   86  190   32]\n",
      " [ 669 3058  185   92   46]\n",
      " [ 321  517 1134   52   15]\n",
      " [ 755  225   45 1024   21]\n",
      " [ 325  216   37   47  435]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.91      0.83      7361\n",
      "          1       0.70      0.76      0.72      4050\n",
      "          2       0.76      0.56      0.64      2039\n",
      "          3       0.73      0.49      0.59      2070\n",
      "          4       0.79      0.41      0.54      1060\n",
      "\n",
      "avg / total       0.74      0.74      0.73     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "- 더 안 좋은 성능\n",
    "- precision은 상승했으나 recall은 많이 악화됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `soyspacing`으로 띄어쓰기 교정한 데이터를 이용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_spacing = load_pickle('../train_space_corrected.pkl')\n",
    "test_spacing = load_pickle('../test_space_corrected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 644 ms, total: 2min 48s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_docs = [(tokenize(row[0]), row[1]) for row in train_spacing]\n",
    "test_docs = [(tokenize(row[0]), row[1]) for row in test_spacing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111922, 37308, 111922, 37308)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = [row[1] for row in train_docs]\n",
    "x0 = [' '.join(row[0]) for row in train_docs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, y0, \n",
    "                                                    random_state=1234)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.77387653  0.77109672  0.77202466  0.77533059  0.77532056]\n",
      "CPU times: user 47.9 s, sys: 1.33 s, total: 49.2 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14531   849   253   648   167]\n",
      " [ 1239  7167   428   209   147]\n",
      " [  511   926  2968   119    43]\n",
      " [ 1230   444    96  2847    59]\n",
      " [  446   417    97   118  1349]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84     16448\n",
      "          1       0.73      0.78      0.75      9190\n",
      "          2       0.77      0.65      0.71      4567\n",
      "          3       0.72      0.61      0.66      4676\n",
      "          4       0.76      0.56      0.64      2427\n",
      "\n",
      "avg / total       0.77      0.77      0.77     37308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 결과\n",
    "\n",
    "- 큰 차이는 없으나 기존 모델보다 향상되지는 않음\n",
    "- 띄어쓰기 교정이 좀 더 제대로 이루어지기 위해서는 띄어쓰기 교정 학습 시 데이터가 더 많고, 더 정교한 처리가 필요할 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = [row[1] for row in test_docs]\n",
    "test_data = [' '.join(row[0]) for row in test_docs]\n",
    "\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6470  394  127  298   72]\n",
      " [ 538 3148  186  107   71]\n",
      " [ 240  418 1298   50   33]\n",
      " [ 547  202   61 1226   34]\n",
      " [ 183  168   32   51  626]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84      7361\n",
      "          1       0.73      0.78      0.75      4050\n",
      "          2       0.76      0.64      0.69      2039\n",
      "          3       0.71      0.59      0.64      2070\n",
      "          4       0.75      0.59      0.66      1060\n",
      "\n",
      "avg / total       0.77      0.77      0.77     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

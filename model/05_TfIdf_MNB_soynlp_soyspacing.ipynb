{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf & Multinomial NB using `soynlp` & `soyspacing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "from words_preprocessing import *\n",
    "from file_io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `soynlp`로 토크나이징한 데이터를 이용한 학습\n",
    "### 기존 모델(`twitter`, 교정X)의 성능"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[16247   984   280   768   177]\n",
    " [ 1238  7903   553   230   171]\n",
    " [  579   966  3319   145    49]\n",
    " [ 1334   502   116  3178    91]\n",
    " [  474   425   100   138  1486]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.88      0.85     18456\n",
    "           1       0.73      0.78      0.76     10095\n",
    "           2       0.76      0.66      0.70      5058\n",
    "           3       0.71      0.61      0.66      5221\n",
    "           4       0.75      0.57      0.65      2623\n",
    "\n",
    " avg / total       0.77      0.78      0.77     41453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165810, 165810)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_pickle('../train_space_corrected.pickle')\n",
    "train_tokenized = load_pickle('../train_space_tokenized.pickle')\n",
    "len(train), len(train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124357, 41453, 124357, 41453)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = [row[1] for row in train_tokenized]\n",
    "x0 = [' '.join(row[0]) for row in train_tokenized]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, y0, \n",
    "                                                    random_state=1234)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.74575862  0.74095368  0.7421897   0.74326498  0.74346602]\n",
      "CPU times: user 50.9 s, sys: 1.92 s, total: 52.8 s\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16729   929   220   491    87]\n",
      " [ 1648  7713   451   179   104]\n",
      " [  866  1212  2824   117    39]\n",
      " [ 1807   632   117  2601    64]\n",
      " [  794   551    82   114  1082]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83     18456\n",
      "          1       0.70      0.76      0.73     10095\n",
      "          2       0.76      0.56      0.65      5058\n",
      "          3       0.74      0.50      0.60      5221\n",
      "          4       0.79      0.41      0.54      2623\n",
      "\n",
      "avg / total       0.75      0.75      0.74     41453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "- 더 안 좋은 성능\n",
    "- precision은 상승했으나 recall은 많이 악화됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `soyspacing`으로 띄어쓰기 교정한 데이터를 이용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 884 ms, total: 3min 1s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124357, 41453, 124357, 41453)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = [row[1] for row in train_docs]\n",
    "x0 = [' '.join(row[0]) for row in train_docs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, y0, \n",
    "                                                    random_state=1234)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.77824234  0.76865552  0.77576294  0.77651789  0.76928026]\n",
      "CPU times: user 54 s, sys: 1.86 s, total: 55.9 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16259   983   277   759   178]\n",
      " [ 1230  7912   554   229   170]\n",
      " [  579   957  3333   141    48]\n",
      " [ 1339   506   118  3168    90]\n",
      " [  483   426   100   140  1474]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85     18456\n",
      "          1       0.73      0.78      0.76     10095\n",
      "          2       0.76      0.66      0.71      5058\n",
      "          3       0.71      0.61      0.66      5221\n",
      "          4       0.75      0.56      0.64      2623\n",
      "\n",
      "avg / total       0.77      0.78      0.77     41453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 결과\n",
    "\n",
    "- 큰 차이는 없으나 기존 모델보다 향상되지는 않음\n",
    "- 띄어쓰기 교정이 좀 더 제대로 이루어지기 위해서는 띄어쓰기 교정 학습 시 데이터가 더 많고, 더 정교한 처리가 필요할 것으로 보임"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf & Multinomial NB (scikit-learn)\n",
    "\n",
    "- tokenizing/POS tagging --> tf-idf vectorizing\n",
    "- model: Multinomial Naive Bayes\n",
    "- train/test: 148861/16539 (라벨링 이후 필터링)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "- Without Oversampling\n",
    "- With Oversampling\n",
    "\n",
    "### Results\n",
    "\n",
    "|                      | Accuracy | Recall | F1-Score |\n",
    "|----------------------|:--------:|:------:|:--------:|\n",
    "| Without Oversampling |   0.77   |  0.77  |   0.77   |\n",
    "| With Obersampling    |   0.86   |  0.86  |   0.86   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from utils import *\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'기쁘다': 73550, '화나다': 40242, '슬프다': 20701, '역겹다': 20325, '무섭다': 10582})\n",
      "\n",
      "기쁘다 : 0.44\n",
      "화나다 : 0.24\n",
      "역겹다 : 0.12\n",
      "슬프다 : 0.13\n",
      "무섭다 : 0.06\n"
     ]
    }
   ],
   "source": [
    "train_joy = read_data('../train_data_labeled_joy.txt')\n",
    "train_anger = read_data('../train_data_labeled_anger.txt')\n",
    "train_disgust = read_data('../train_data_labeled_disgust.txt')\n",
    "train_sadness = read_data('../train_data_labeled_sadness.txt')\n",
    "train_fear = read_data('../train_data_labeled_fear.txt')\n",
    "\n",
    "trains = [train_joy, train_anger, train_disgust, train_sadness, train_fear]\n",
    "labels = ['기쁘다', '화나다', '역겹다', '슬프다', '무섭다']\n",
    "\n",
    "num_dic = {}\n",
    "for label, data in zip(labels, trains):\n",
    "    num_dic[label] = len(data)\n",
    "label_count = Counter(num_dic)\n",
    "print(label_count)\n",
    "print()\n",
    "\n",
    "sum_ = sum(label_count.values())\n",
    "for label in label_count.keys():\n",
    "    print(label ,\":\", round(label_count[label] / sum_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- '기쁘다'의 데이터양은 44%인데 비해 '무섭다'는 6% --> 오버샘플링 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def pop_test(data, length):\n",
    "    result = [data.pop(random.randrange(len(data))) for _ in range(length)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_joy = pop_test(train_joy, len(train_joy)//10)\n",
    "test_anger = pop_test(train_anger, len(train_anger)//10)\n",
    "test_disgust = pop_test(train_disgust, len(train_disgust)//10)\n",
    "test_sadness = pop_test(train_sadness, len(train_sadness)//10)\n",
    "test_fear = pop_test(train_fear, len(train_fear)//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_joy_labeled = [(row, 0) for row in train_joy]\n",
    "train_anger_labeled = [(row, 1) for row in train_anger]\n",
    "train_disgust_labeled = [(row, 2) for row in train_disgust]\n",
    "train_sadness_labeled = [(row, 3) for row in train_sadness]\n",
    "train_fear_labeled = [(row, 4) for row in train_fear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_joy_labeled = [(row, 0) for row in test_joy]\n",
    "test_anger_labeled = [(row, 1) for row in test_anger]\n",
    "test_disgust_labeled = [(row, 2) for row in test_disgust]\n",
    "test_sadness_labeled = [(row, 3) for row in test_sadness]\n",
    "test_fear_labeled = [(row, 4) for row in test_fear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lst = [train_joy_labeled, train_anger_labeled, \n",
    "             train_disgust_labeled, train_sadness_labeled, train_fear_labeled]\n",
    "test_lst = [test_joy_labeled, test_anger_labeled,\n",
    "            test_disgust_labeled, test_sadness_labeled, test_fear_labeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148861 16539\n"
     ]
    }
   ],
   "source": [
    "train, test = [], []\n",
    "for data in train_lst:\n",
    "    train += data\n",
    "\n",
    "for data in test_lst:\n",
    "    test += data\n",
    "    \n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle('../train_labeled_0503.pickle', train)\n",
    "save_pickle('../test_labeled_0503.pickle', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 1.13 s, total: 3min 10s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_docs = [(tokenize(row[0][0]), row[1]) for row in train]\n",
    "test_docs = [(tokenize(row[0][0]), row[1]) for row in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle('../train_docs_0503.pickle', train_docs)\n",
    "save_pickle('../test_docs_0503.pickle', test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = [row[1] for row in train_docs]\n",
    "x0 = [' '.join(row[0]) for row in train_docs]\n",
    "\n",
    "test_label = [row[1] for row in test_docs]\n",
    "test_data = [' '.join(row[0]) for row in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111645, 37216, 111645, 37216)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x0, y0, \n",
    "                                                    random_state=1234)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.77251355  0.77277206  0.77622033  0.76920321  0.77453308]\n",
      "CPU times: user 48.2 s, sys: 1.58 s, total: 49.8 s\n",
      "Wall time: 49.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14577   861   248   713   158]\n",
      " [ 1119  7066   433   226   149]\n",
      " [  533   909  3015   158    52]\n",
      " [ 1176   450    98  2837    77]\n",
      " [  437   428    84    99  1313]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85     16557\n",
      "          1       0.73      0.79      0.76      8993\n",
      "          2       0.78      0.65      0.71      4667\n",
      "          3       0.70      0.61      0.65      4638\n",
      "          4       0.75      0.56      0.64      2361\n",
      "\n",
      "avg / total       0.77      0.77      0.77     37216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**05/03**\n",
    "- '기쁘다' 필터링 이후, '슬프다' precision 약간 감소 (0.72 --> 0.70)\n",
    "    - 긍/부정 동시 등장 제거\n",
    "    - 반어법 제거\n",
    "- '무섭다' precision 0.01 감소, recall 0.02 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습에 사용되지 않은 데이터로 Prediction\n",
    "- 단 데이터 자체는 train과 같이 가공되었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6497  379  105  294   80]\n",
      " [ 500 3151  208  103   62]\n",
      " [ 229  398 1312   71   22]\n",
      " [ 519  191   44 1282   34]\n",
      " [ 167  208   31   60  592]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85      7355\n",
      "          1       0.73      0.78      0.75      4024\n",
      "          2       0.77      0.65      0.70      2032\n",
      "          3       0.71      0.62      0.66      2070\n",
      "          4       0.75      0.56      0.64      1058\n",
      "\n",
      "avg / total       0.77      0.78      0.77     16539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링 이후 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x0).reshape(-1, 1)\n",
    "X, y = RandomOverSampler(random_state=1234).fit_sample(x, y0)\n",
    "X = [x[0] for x in X.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330975, 330975)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 66195, 1: 66195, 2: 66195, 3: 66195, 4: 66195})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248231, 82744, 248231, 82744)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, \n",
    "                                                        random_state=1234)\n",
    "\n",
    "len(X_train2), len(X_test2), len(y_train2), len(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...e,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, ngram_range=(1, 3))), \n",
    "    ('clf', MultinomialNB(alpha=0.001)),    \n",
    "])\n",
    "\n",
    "model2 = clf2.fit(X_train2, y_train2)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [ 0.84438447  0.84389792  0.84254839  0.84556661  0.84448966]\n",
      "CPU times: user 1min 43s, sys: 3.23 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores2 = cross_val_score(clf2, X_train2, y_train2, cv=5)\n",
    "print(\"Cross validation score: {}\".format(scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12677  1062   620  1598   470]\n",
      " [ 1137 13315  1051   530   463]\n",
      " [  486   895 14665   300   185]\n",
      " [  958   681   256 14496   238]\n",
      " [  289   313   133   195 15731]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.77      0.79     16427\n",
      "          1       0.82      0.81      0.81     16496\n",
      "          2       0.88      0.89      0.88     16531\n",
      "          3       0.85      0.87      0.86     16629\n",
      "          4       0.92      0.94      0.93     16661\n",
      "\n",
      "avg / total       0.86      0.86      0.86     82744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오버샘플링 이후 recall 상승\n",
    "- precision/recall 크게 상승 (특히 역겹다/슬프다/무섭다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = model2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5650  496  304  662  243]\n",
      " [ 381 2916  390  186  151]\n",
      " [ 142  322 1411  100   57]\n",
      " [ 313  162   74 1436   85]\n",
      " [ 107  158   57   66  670]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_label, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.77      0.81      7355\n",
      "          1       0.72      0.72      0.72      4024\n",
      "          2       0.63      0.69      0.66      2032\n",
      "          3       0.59      0.69      0.64      2070\n",
      "          4       0.56      0.63      0.59      1058\n",
      "\n",
      "avg / total       0.74      0.73      0.73     16539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle('../model/mnb_0503.pickle', model)\n",
    "save_pickle('../model/mnb_0503_ov.pickle', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

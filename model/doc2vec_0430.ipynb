{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_pickle('../train_labeled_0430.pickle')\n",
    "test = load_pickle('../test_labeled_0430.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\"\"\"미소가 찾아갈 친구에겐 불편할 수도 있는 이야기. 하지만 미소에겐, 미소를 받아들인 이에겐, 미소를 지켜보는 관중들에겐 불편함은 없었다. 사랑하는 위스키와 담배를 위해 집을 포기한 미소에게, 나아가 약마저 포기한 미소에게 누가 가벼이 말할 수 있나\"\"\"'],\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_docs = [(tokenize(row[0][0]), row[1]) for row in train]\n",
    "test_docs = [(tokenize(row[0][0]), row[1]) for row in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152479, 16940)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 398 ms, sys: 13.9 ms, total: 412 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs]\n",
    "tagged_test_docs = [TaggedDocument(d, [c]) for d, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec(size=300, alpha=0.02, min_alpha=0.02, \n",
    "                        workers=4, min_count=10, iter=100, seed=1234)\n",
    "model.build_vocab(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 8s, sys: 6min 38s, total: 24min 46s\n",
      "Wall time: 13min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "222309735"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(tagged_train_docs, epochs=model.iter, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../model/doc2vec_0430_alpha002.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152479\n",
      "300\n",
      "CPU times: user 31.9 s, sys: 516 ms, total: 32.4 s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [model.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags[0] for doc in tagged_train_docs]\n",
    "print(len(X_train))\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16940\n",
      "0\n",
      "CPU times: user 3.61 s, sys: 11.8 ms, total: 3.62 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = [model.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "y_test = [doc.tags[0] for doc in tagged_test_docs]\n",
    "print(len(X_test))\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 1.08 s, total: 27.8 s\n",
      "Wall time: 28.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5711334120425029"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018/04/30 02:30**\n",
    "\n",
    "- scikit-learn classifier 결과 (BaseLine)\n",
    "    - LogisticRegression: 57% (매우 나쁜 성능)\n",
    "    - NB는 음수가 들어가면 error 발생 --> scaling 후 시도해야 할 듯\n",
    "- train data 조정 필요할 듯\n",
    "- `norm/stem` --> 의미 정보가 상당부분 희석되는 문제 발생 (train set 최대한 깔끔하게 조성 시도해야 할 듯)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
